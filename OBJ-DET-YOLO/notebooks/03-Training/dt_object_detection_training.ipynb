{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shRmyOAbatwZ"
      },
      "outputs": [],
      "source": [
        "# Create a temporary workspace\n",
        "import tempfile\n",
        "\n",
        "\n",
        "SESSION_WORKSPACE = tempfile.mkdtemp()\n",
        "print(f\"Session workspace created at: {SESSION_WORKSPACE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iod0c4KF_Vxo"
      },
      "outputs": [],
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhdlb1osbf_a"
      },
      "outputs": [],
      "source": [
        "# Unzip the dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR_NAME = \"duckietown_object_detection_dataset\"\n",
        "DATASET_ZIP_NAME = f\"{DATASET_DIR_NAME}.zip\"\n",
        "DATASET_DIR_PATH = os.path.join(SESSION_WORKSPACE, DATASET_DIR_NAME)\n",
        "TRAIN_DIR = \"train\"\n",
        "VALIDATION_DIR = \"val\"\n",
        "IMAGES_DIR = \"images\"\n",
        "LABELS_DIR = \"labels\"\n",
        "\n",
        "\n",
        "def show_info(base_path: str):\n",
        "  for l1 in [TRAIN_DIR, VALIDATION_DIR]:\n",
        "    for l2 in [IMAGES_DIR, LABELS_DIR]:\n",
        "      p = os.path.join(base_path, l1, l2)\n",
        "      print(f\"#Files in {l1}/{l2}: {len(os.listdir(p))}\")\n",
        "\n",
        "\n",
        "def unzip_dataset():\n",
        "  # check zipped file\n",
        "  zip_path = os.path.join(DRIVE_PATH, DATASET_ZIP_NAME)\n",
        "  assert os.path.exists(zip_path), f\"No zipped dataset found at {zip_path}! Abort!\"\n",
        "\n",
        "  # unzip the data\n",
        "  print(\"Unpacking zipped data...\")\n",
        "  shutil.unpack_archive(zip_path, DATASET_DIR_PATH)\n",
        "  print(f\"Zipped dataset unpacked to {DATASET_DIR_PATH}\")\n",
        "\n",
        "  # show some info\n",
        "  show_info(DATASET_DIR_PATH)\n",
        "\n",
        "\n",
        "unzip_dataset()\n",
        "# change  working directory to the session workspace\n",
        "os.chdir(SESSION_WORKSPACE)\n",
        "print(f\"PWD: {os.getcwd()}\")\n",
        "\n",
        "# install pytorch and torchvision\n",
        "!pip3 install torch==1.13.0 torchvision==0.14.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8L68QAeZF9G"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git -b v7.0\n",
        "!cd yolov5 && pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5iilV-e76YN"
      },
      "source": [
        "# We now inform the training process of the format and location of our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u3D124u8Flw"
      },
      "outputs": [],
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../duckietown_object_detection_dataset/train\n",
        "val: ../duckietown_object_detection_dataset/val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take about 5 minutes.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kss7Oid6OkAv"
      },
      "outputs": [],
      "source": [
        "!cd yolov5 && python3 train.py --cfg ./models/yolov5n.yaml --img 416 --batch 32 --epochs 10 --data duckietown.yaml --weights yolov5n.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5jSQ4XubFqH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")\n",
        "print(f\"Marked the model from the latest run ({latest_exp}) as yolov5/best.pt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!\n",
        "\n",
        "We will need our token to access our personal cloud space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hl-HhnrFtKnp"
      },
      "outputs": [],
      "source": [
        "\n",
        "YOUR_DT_TOKEN = \"dt1-3nT7FDbT7NLPrXykNJW6pwkBovEH6ibVT2G4FWC5GPruqvC-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfTXrSZ2uzXpRS1VrEPDjScTfphNbDEgaQJ\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCd7RrjLc64Z"
      },
      "source": [
        "Then, we chose the location of the trained model on disk and its name once uploaded to our cloud space. You should not change these values, or the robots will not be able to find the model to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4bNXEgAFpRIH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dt-data-api-daffy in /home/ayush/.local/lib/python3.8/site-packages (1.2.0)\n",
            "Requirement already satisfied: lxml in /home/ayush/.local/lib/python3.8/site-packages (from dt-data-api-daffy) (4.9.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from dt-data-api-daffy) (2.22.0)\n",
            "Requirement already satisfied: dt-authentication-daffy in /home/ayush/.local/lib/python3.8/site-packages (from dt-data-api-daffy) (0.1.16)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/ayush/.local/lib/python3.8/site-packages (from dt-data-api-daffy) (4.12.2)\n",
            "Requirement already satisfied: base58 in /home/ayush/.local/lib/python3.8/site-packages (from dt-authentication-daffy->dt-data-api-daffy) (2.1.1)\n",
            "Requirement already satisfied: ecdsa in /home/ayush/.local/lib/python3.8/site-packages (from dt-authentication-daffy->dt-data-api-daffy) (0.18.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/ayush/.local/lib/python3.8/site-packages (from beautifulsoup4->dt-data-api-daffy) (2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from ecdsa->dt-authentication-daffy->dt-data-api-daffy) (1.14.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, './yolov5_v2')\n",
        "\n",
        "# DO NOT CHANGE THESE\n",
        "model_name = \"yolov5n_v2\"\n",
        "model_local_path = \"./yolov5_v2/best.pt\"\n",
        "model_remote_path = f\"courses/mooc/objdet/data/nn_models/{model_name}.pt\"\n",
        "\n",
        "# install DCSS client\n",
        "!pip3 install dt-data-api-daffy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DYodvDdQKr"
      },
      "source": [
        "We now open a pointer to our cloud space and upload the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NAU4dTNJVkyx"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The file /home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/yolov5_v2 does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/dt_object_detection_training.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/dt_object_detection_training.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m storage \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mstorage(\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/dt_object_detection_training.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# upload model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/dt_object_detection_training.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m upload \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mupload(model_local_path, model_remote_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/dt_object_detection_training.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m upload\u001b[39m.\u001b[39mjoin()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/dt_data_api/storage.py:318\u001b[0m, in \u001b[0;36mStorage.upload\u001b[0;34m(self, source, destination, length)\u001b[0m\n\u001b[1;32m    316\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(source)\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(file_path):\n\u001b[0;32m--> 318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    319\u001b[0m source \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(file_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m source_len \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mgetsize(file_path)\n",
            "\u001b[0;31mValueError\u001b[0m: The file /home/ayush/Downloads/duckietown-lx-mooc2022/object-detection/notebooks/03-Training/yolov5_v2 does not exist."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from dt_data_api import DataClient, Storage\n",
        "\n",
        "# open a pointer to our personal duckietown cloud space\n",
        "client = DataClient(YOUR_DT_TOKEN)\n",
        "storage = client.storage(\"user\")\n",
        "\n",
        "# upload model\n",
        "upload = storage.upload(model_local_path, model_remote_path)\n",
        "upload.join()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can now close this tab and go back to the `Training` notebook"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
